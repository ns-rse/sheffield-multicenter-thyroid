---
title: "An investigation of the predictors of Thyroid Cancer"
author:
  - name: Ovie Edafe
    orcid: 0000-0002-6205-806X
    corresponding: true
    email: ovieedafe@hotmail.co.uk
    roles:
      - Researcher
    affiliations:
      - Department of Oncology & Metabolism, University of Sheffield
  - name: Neil Shephard
    orcid: 000-0001-8301-6857
    corresponding: false
    email:
    roles:
      - Researcher
    affiliations:
      - Research Software Engineer, Department of Computer Science, University of Sheffield
  - name: Sabapathy P Balasubramanian
    orcid: 0000-0001-5953-2843
    corresponding: false
    roles: Researcher
    affiliations:
      - Directorate of General Surgery, Sheffield Teaching Hospitals NHS Foundation Trust
abstract: |
  ### Introduction {.unnumbered}

  This is the introduction.

  ### Methods {.unnumbered}

  This is the methods.

  ### Results {.unnumbered}

  This is the results.

  ### Conclusion {.unnumbered}

  This is the conclusion
keywords:
  - Thyroid nodules
  - Thyroid cancer
plain-language-summary: |
    Plain language summary
key-points:
  - Key point 1
  - Key point 2
date: 2024-04-26
bibliography: references.bib
citation:
  container-title: "Sheffield study on thyroid nodules"
number-sections: true
---

```{r}
#| label: setup
#| purl: true
#| eval: true
#| echo: false
#| warning: false

# Libraries for data manipulation, plotting and tabulating (sorted alphabetically)
library(dplyr)
library(ggplot2)
library(ggdark)
library(gtsummary)
library(Hmisc)
library(knitr)
library(readr)
library(rmarkdown)

# Libraries for Tidymodelling
library(dials)
library(kernlab)
library(knitr)
library(tidymodels)
library(tidyverse)
library(vip)

# Set global options
options(digits = 3)
train <- 0.75
test <- 0.25

## Set directories based on current location
base_dir <- getwd()
data_dir <- paste(base_dir, "data", sep = "/")
csv_dir <- paste(data_dir, "csv", sep = "/")
r_dir <- paste(data_dir, "r", sep = "/")
r_scripts <- paste(base_dir, "r", sep = "/")


## Load data
##
## The following line runs the `r/shf_thy_nod.R` script which reads the data from CSV and cleans/tidies it.
## If something has changed in that file or the underlying data (in `data/csv/sheffield_thyroid_module.R`) then this
## line should be uncommented and the code will run. At the end of the file it saves the data to `data/r/clean.rds`.
source("r/shf_thy_nod.R")
## If nothing has changed in the underlying data or the cleaning/tidying process then the last version of the data,
## saved to `data/r/clean.rds` can be loaded cy commenting out the line above and uncommenting the line below.
#df <- readRDS(paste(r_dir, "clean.rds", sep="/"))
```


## Introduction

Some paragraphs on the background of the work can go here. **TODO** Expand on this.


## Methods

Data was cleaned and analysed using the R Statistical Software @r_citation and the Tidyverse (@tidyverse),  Tidymodels
(@tidymodels) collection of packages.

### Modelling

Description of the different models and how they are assessed can go here.

A selection of modern statistical inference approaches have been selected and tested for this work. To fit the models
data is split into training and testing cohorts in a ratio of `r train`:`r test` and each model is fitted using the
training cohort. The predictive accuracy of the fitted model is then assessed in the test cohort. **TODO** Expand on this.

Cross validation is used to estimate the accuracy of the models there are a number of options available, those
considered for this work are k-fold and leave one out (loo) cross-validation. **TODO** Expand on this.

#### LASSO / Elastic Net

LASSO (Least Absolute Shrinkage and Selection Operatror) and Elastic Net @zou2005 are regression methods that perform variable
selection. The original LASSO method proposed by @tibshirani1996 allows the coefficients for independent/predictor
variables to "shrink" down towards zero, effectively eliminating them from influencing the model, this is often referred
to as L<sub>1</sub> regularisation. The Elastic Net @zou2005 improves on the LASSO by balancing L<sub>1</sub>
regularisation with ridge-regression or L<sub>2</sub> regularisation which helps avoid over-fitting.

Both methods avoid many of the shortcomings/pitfalls of stepwise variable selection @thompson1995 @smith2018 and have
been shown to be more accurate in clinical decision making in small datasets with well code, externally selected
variables @steyerberg2001



#### Random Forest

Blurb on what Random Forests are.

#### Gradient Boosting

Blurb on what Gradient Boosting is.

#### SVM

Blurb on what Support Vector Machines are.

#### Comparision



## Results

### Data Description

Details of data completeness and other descriptive aspects go here.


```{r}
#| label: tbl-variables
#| purl: true
#| eval: true
#| echo: false
#| warning: false
#| tbl-caption: "Description of variables in the Sheffield Thyroid dataset."
var_labels |>
  as.data.frame() |>
  kable(col.names = c("Description"),
        caption="Description of variables in the Sheffield Thyroid dataset.")
```

A summary of the variables that are available in this data set can be found in @tbl-variables.


```{r}
#| label: tbl-data-completeness
#| purl: true
#| eval: true
#| echo: false
#| warning: false
#| tbl-caption: "Overall summary of all variables in the Sheffield dataset."
df_summary <- df |>
  dplyr::ungroup() |>
  gtsummary::tbl_summary(
    type = all_continuous() ~ "continuous2",
    statistic = all_continuous() ~ c(
      "{N_nonmiss}",
      "{mean} ({sd})",
      "{median} ({p25}, {p75})",
      "{min}, {max}"
    ),
    percent="column",      # Include percentages for categorical variables by "column", "row" or "cell"
    missing="always"           # Exclude missing, options are "no", "ifany" and "always"
  ) |>
  gtsummary::modify_caption("Baseline characteristics and referral source of included patients")
df_summary

```

The completeness of the data is shown in @tbl-data-completeness. Where variables continuous (e.g. `age` or
`size_nodule_mm`) basic summary statistics in the form of mean, standard deviation, median and inter-quartile range are
given. For categorical variables that are logical `TRUE`/`FALSE` (e.g. `palpable_nodule`) the number of `TRUE`
observations and the percentage (of those with observed data for that variable) are shown along with the number that are
_Unknown_. For categorical variables such as `gender` and percentages in each category are
reported. For all variables an indication of the number of missing observations is also given

**IMPORTANT** Once you have decided which variables you want to include in your analysis you should determine how many
individuals have complete data for all of these, this _will_ reduce your sample size available.

The predictor variables selected for inclusion were.

**TODO** Insert table of subset of predictor variables.

```{r}
#| label: test-train-split
#| purl: true
#| eval: true
#| echo: false
#| output: false
## Prefer tidymodel commands (although in most places we use the convention <pkg>::<function>())
tidymodels_prefer()
set.seed(5039378)

## This is the point at which you should subset your data for those who have data available for the variables of
## interest. The variables here should include the outcome `final_pathology` and the predictor variables that are set in
## the code chunk `recipe`. May want to move this to another earlier in the processing so that the number of rows can be
## counted and reported.
df_complete <- df |>
  dplyr::select(
    age_at_scan,
    final_pathology,
    gender,
    palpable_nodule,
    rapid_enlargment,
    size_nodule_mm,
    thy_classification) |>
dplyr::filter(if_any(everything(), is.na))

## Use the df_complete rather than df as this subset have data for all the variables of interest.
split <- rsample::initial_split(df_complete, prop = 0.75)
train <- rsample::training(split)
test <- rsample::testing(split)
```

```{r}
#| label: cv-vfold
#| purl: true
#| eval: true
#| echo: false
#| output: false
cv_folds <- rsample::vfold_cv(train, v = 10, repeats = 10)
```

```{r}
#| label: cv-loo
#| purl: true
#| eval: true
#| echo: false
#| output: false
cv_loo <- rsample::loo_cv(train)
```
```{r}
#| label: recipe
#| purl: true
#| eval: true
#| echo: true
#| output: false
## NB This is the key section where the variables that are to be used in the model are defined. A dependant variable
## (the outcome of interest) is in this case the `final_pathology`, whether individuals have malignant or benign tumors,
## this appears on the left-hand side of the equation (before the tilde `~`). On the right of the equation are the
## predictor or dependant variables
thyroid_recipe <- recipes::recipe(final_pathology ~ gender + size_nodule_mm + age_at_scan + palpable_nodule +
  rapid_enlargment + thy_classification, data = train) |>
  recipes::step_num2factor(final_pathology, levels = c("Benign", "Malignant")) |>
  recipes::step_dummy(gender, asa_score, smoking_status, nodule_fna_thy) |>
  recipes::step_normalize(all_numeric())
```

### Modelling

A total of `r df_complete |> nrow()` patients had complete data for the selected predictor variables (see
@tbl-predictors).

Results of the various modelling go here. Each section will show the results along with...

+ LIME/Shaply analysis for explanability of models


#### LASSO / Elastic Net

#### Random Forest

#### Gradient Boosting

#### SVM

#### Comparision

Comparing the sensitivity of the different models goes here.

+ Table of sensitivit/specificit/other metrics.
+ ROC curves

## Conclusion

The take-away message is....these things are hard!
